{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled17.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "atct38o_s3ZB"
      },
      "source": [
        "# Sentiment Analysis with ParsBERT"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The NVIDIA System Management Interface (nvidia-smi) is a command line utility, based on top of the NVIDIA Management Library (NVML), intended to aid in the management and monitoring of NVIDIA GPU devices."
      ],
      "metadata": {
        "id": "L9Nvlm0tAwGc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9HbUK_disBly"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install & import Libraries"
      ],
      "metadata": {
        "id": "zZ7ugLdoA9-7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "iB2TDd3asGTx"
      },
      "outputs": [],
      "source": [
        "# Import required packages (If You Need Any More Packages, You Can Add them HERE.)\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "import os\n",
        "import re\n",
        "import collections"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YnGajnQGQIIX"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cCTKvthyQlOG"
      },
      "source": [
        "### Load the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DNx25HZyQI8H"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/SBU-CE/Deep-Learning.git\n",
        "data = pd.read_csv('/content/Deep-Learning/spring-2022/assignments/project-3/taghche_5000.csv', encoding='utf-8')\n",
        "data = data[['comment', 'rate']]\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YjjHSjyeQvqb"
      },
      "outputs": [],
      "source": [
        "# handle some conflicts with the dataset structure\n",
        "# you can find a reliable solution, for the sake of the simplicity\n",
        "# I just remove these bad combinations!\n",
        "data['rate'] = data['rate'].apply(lambda r: r if r < 6 else None)\n",
        "\n",
        "data = data.dropna(subset=['rate'])\n",
        "data = data.dropna(subset=['comment'])\n",
        "data = data.drop_duplicates(subset=['comment'], keep='first')\n",
        "data = data.reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CWmMbGFCQ1Rf"
      },
      "source": [
        "### Normalization / Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wMn63nr5RCz2"
      },
      "source": [
        "**<font color=red> For simplicity, Transform the rate in a range of 0.0 to 5.0 to a binary form of negative (0) or positive (1) with a threshold. If the rate is less than 3.0, it labeled as negative otherwise specified as positive.</font>**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##############################################################################################\n",
        "#                                       Your Code                                            #\n",
        "##############################################################################################"
      ],
      "metadata": {
        "id": "OlqXeDLwLWx5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fCQfM5DmRGG-"
      },
      "source": [
        "**<font color=red> Cleaning is the final step in this section. Your cleaned method should be included these steps:</font>**\n",
        "\n",
        "**<font color=red>- fixing unicodes</font>**\n",
        "\n",
        "**<font color=red>- removing specials like a phone number, email, url, new lines, ...</font>**\n",
        "\n",
        "**<font color=red>- cleaning HTMLs</font>**\n",
        "\n",
        "**<font color=red>- normalizing</font>**\n",
        "\n",
        "**<font color=red>- removing emojis</font>**\n",
        "\n",
        "**<font color=red>- removing extra spaces, hashtags</font>**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CRX3CZT6REFh"
      },
      "outputs": [],
      "source": [
        "def cleaning(text):\n",
        "    text = text.strip()\n",
        "\n",
        "    ##############################################################################################\n",
        "    #                                       Your Code                                            #\n",
        "    ##############################################################################################\n",
        "    \n",
        "    \n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "681o2WMERHbJ"
      },
      "outputs": [],
      "source": [
        "# cleaning comments\n",
        "data['cleaned_comment'] = data['comment'].apply(cleaning)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**<font color=red> Calculate the Length of Comments based on their Words</font>**"
      ],
      "metadata": {
        "id": "asSwiNKxPaAz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ioFL5_1MQzIb"
      },
      "outputs": [],
      "source": [
        "##############################################################################################\n",
        "#                                       Your Code                                            #\n",
        "##############################################################################################"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**<font color=red> Remove Comments with the Length of Fewer than 3 Words & More than 256 Words</font>**"
      ],
      "metadata": {
        "id": "TDwxjxkJPpyY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kliWRX7-3U1c"
      },
      "outputs": [],
      "source": [
        "##############################################################################################\n",
        "#                                       Your Code                                            #\n",
        "##############################################################################################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GlBnHyl0RIzx"
      },
      "outputs": [],
      "source": [
        "data = data[['cleaned_comment', 'label']]\n",
        "data.columns = ['comment', 'label']\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ny0D77atzqWT"
      },
      "source": [
        "### Handling Unbalanced Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Q0yEPxd-tb-"
      },
      "source": [
        "**<font color=red> Because the Data is Unbalanced, You should Balance it. Before & After Balancing Data, You should Plot a Bar Chart of Distribution of label within comments [DATA]</font>**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##############################################################################################\n",
        "#                                       Your Code                                            #\n",
        "##############################################################################################"
      ],
      "metadata": {
        "id": "8rhzPbMURPyK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RpLObddZROJm"
      },
      "source": [
        "## Train,Validation,Test split\n",
        "\n",
        "To achieve a globalized model, we need to split the cleaned dataset into train, valid, test sets due to size of the data. In this tutorial, I have considered a rate of **0.1** for both *valid*, *test* sets. For splitting, I use `train_test_split` provided by Sklearn package with stratifying on the label for preserving the distribution balance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DR_4CTGERLyw"
      },
      "outputs": [],
      "source": [
        "new_data['label_id'] = new_data['label'].apply(lambda t: labels.index(t))\n",
        "\n",
        "train, test = train_test_split(new_data, test_size=0.1, random_state=1, stratify=new_data['label'])\n",
        "train, valid = train_test_split(train, test_size=0.1, random_state=1, stratify=train['label'])\n",
        "\n",
        "train = train.reset_index(drop=True)\n",
        "valid = valid.reset_index(drop=True)\n",
        "test = test.reset_index(drop=True)\n",
        "\n",
        "x_train, y_train = train['comment'].values.tolist(), train['label_id'].values.tolist()\n",
        "x_valid, y_valid = valid['comment'].values.tolist(), valid['label_id'].values.tolist()\n",
        "x_test, y_test = test['comment'].values.tolist(), test['label_id'].values.tolist()\n",
        "\n",
        "print(train.shape)\n",
        "print(valid.shape)\n",
        "print(test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17sghNPPRaOz"
      },
      "source": [
        "![BERT INPUTS](https://res.cloudinary.com/m3hrdadfi/image/upload/v1595158991/kaggle/bert_inputs_w8rith.png)\n",
        "\n",
        "As you may know, the BERT model input is a combination of 3 embeddings.\n",
        "- Token embeddings: WordPiece token vocabulary (WordPiece is another word segmentation algorithm, similar to BPE)\n",
        "- Segment embeddings: for pair sentences [A-B] marked as $E_A$ or $E_B$ mean that it belongs to the first sentence or the second one.\n",
        "- Position embeddings: specify the position of words in a sentence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mk-T5EvIRc6t"
      },
      "source": [
        "## PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LjfRss-DR3fu"
      },
      "outputs": [],
      "source": [
        "# Import required packages (If You Need Any More Packages, You Can Add them HERE.)\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SperdZDDWKxT"
      },
      "source": [
        "### Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WFpUoggdpU3x"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f'device: {device}')\n",
        "\n",
        "train_on_gpu = torch.cuda.is_available()\n",
        "\n",
        "if not train_on_gpu:\n",
        "    print('CUDA is not available.  Training on CPU ...')\n",
        "else:\n",
        "    print('CUDA is available!  Training on GPU ...')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mH38OJU0X7rd"
      },
      "outputs": [],
      "source": [
        "# general config\n",
        "MAX_LEN = 128\n",
        "TRAIN_BATCH_SIZE = 16\n",
        "VALID_BATCH_SIZE = 16\n",
        "TEST_BATCH_SIZE = 16\n",
        "\n",
        "EPOCHS = 10\n",
        "EEVERY_EPOCH = 1000\n",
        "LEARNING_RATE = 2e-5\n",
        "CLIP = 0.0\n",
        "\n",
        "OUTPUT_PATH = '/content/bert-fa-base-uncased-sentiment-taaghceh/pytorch_model.bin'\n",
        "\n",
        "os.makedirs(os.path.dirname(OUTPUT_PATH), exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qK02AC0pYIPj"
      },
      "outputs": [],
      "source": [
        "# create a key finder based on label 2 id and id to label\n",
        "\n",
        "label2id = {label: i for i, label in enumerate(labels)}\n",
        "id2label = {v: k for k, v in label2id.items()}\n",
        "\n",
        "print(f'label2id: {label2id}')\n",
        "print(f'id2label: {id2label}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**<font color=red> Setup the Tokenizer and Configuration</font>**"
      ],
      "metadata": {
        "id": "EBjLAydrU8jN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qGJRNBXFYOcx"
      },
      "outputs": [],
      "source": [
        "##############################################################################################\n",
        "#                                       Your Code                                            #\n",
        "##############################################################################################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cr9L9N91gSpm"
      },
      "source": [
        "### Input Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pr8cRm9xiyKh"
      },
      "source": [
        "### Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TaJBSSuMizgr"
      },
      "outputs": [],
      "source": [
        "class TaaghcheDataset(torch.utils.data.Dataset):\n",
        "    \"\"\" Create a PyTorch dataset for Taaghche. \"\"\"\n",
        "\n",
        "    def __init__(self, tokenizer, comments, targets=None, label_list=None, max_len=128):\n",
        "        self.comments = comments\n",
        "        self.targets = targets\n",
        "        self.has_target = isinstance(targets, list) or isinstance(targets, np.ndarray)\n",
        "\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "        \n",
        "        self.label_map = {label: i for i, label in enumerate(label_list)} if isinstance(label_list, list) else {}\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.comments)\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        comment = str(self.comments[item])\n",
        "\n",
        "        if self.has_target:\n",
        "            target = self.label_map.get(str(self.targets[item]), str(self.targets[item]))\n",
        "\n",
        "        encoding = self.tokenizer.encode_plus(\n",
        "            comment,\n",
        "            add_special_tokens=True,\n",
        "            truncation=True,\n",
        "            max_length=self.max_len,\n",
        "            return_token_type_ids=True,\n",
        "            padding='max_length',\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt')\n",
        "        \n",
        "        inputs = {\n",
        "            'comment': comment,\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'token_type_ids': encoding['token_type_ids'].flatten(),\n",
        "        }\n",
        "\n",
        "        if self.has_target:\n",
        "            inputs['targets'] = torch.tensor(target, dtype=torch.long)\n",
        "        \n",
        "        return inputs\n",
        "\n",
        "\n",
        "def create_data_loader(x, y, tokenizer, max_len, batch_size, label_list):\n",
        "    dataset = TaaghcheDataset(\n",
        "        comments=x,\n",
        "        targets=y,\n",
        "        tokenizer=tokenizer,\n",
        "        max_len=max_len, \n",
        "        label_list=label_list)\n",
        "    \n",
        "    return torch.utils.data.DataLoader(dataset, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JEcefj6fkZFl"
      },
      "outputs": [],
      "source": [
        "label_list = ['negative', 'positive']\n",
        "train_data_loader = create_data_loader(train['comment'].to_numpy(), train['label'].to_numpy(), tokenizer, MAX_LEN, TRAIN_BATCH_SIZE, label_list)\n",
        "valid_data_loader = create_data_loader(valid['comment'].to_numpy(), valid['label'].to_numpy(), tokenizer, MAX_LEN, VALID_BATCH_SIZE, label_list)\n",
        "test_data_loader = create_data_loader(test['comment'].to_numpy(), None, tokenizer, MAX_LEN, TEST_BATCH_SIZE, label_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "doP5OE1OWP38"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**<font color=red> Complete forward function</font>**"
      ],
      "metadata": {
        "id": "FqhHjIUQYq3Y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mv75ARn_R_Dt"
      },
      "outputs": [],
      "source": [
        "class SentimentModel(nn.Module):\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super(SentimentModel, self).__init__()\n",
        "\n",
        "        self.bert = BertModel.from_pretrained(MODEL_NAME_OR_PATH)\n",
        "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "        self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n",
        "    \n",
        "    def forward(self):\n",
        "        ##############################################################################################\n",
        "        #                                       Your Code                                            #\n",
        "        ##############################################################################################\n",
        "        return None "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VrObbZAdNTNl"
      },
      "outputs": [],
      "source": [
        "import torch, gc\n",
        "\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "pt_model = None\n",
        "\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7vzQGZGUmw3-"
      },
      "outputs": [],
      "source": [
        "pt_model = SentimentModel(config=config)\n",
        "pt_model = pt_model.to(device)\n",
        "\n",
        "print('pt_model', type(pt_model))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFZQDfLlp0Sf"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**<font color=red> Complete functions</font>**"
      ],
      "metadata": {
        "id": "2f8_XjYbcdUv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e044fZSfBoKe"
      },
      "outputs": [],
      "source": [
        "def acc_and_f1(y_true, y_pred, average='weighted'):\n",
        "    # Define Accuracy and F1-score\n",
        "    ##############################################################################################\n",
        "    #                                       Your Code                                            #\n",
        "    ##############################################################################################\n",
        "    return None, None\n",
        "\n",
        "def y_loss(y_true, y_pred, losses):\n",
        "    y_true = torch.stack(y_true).cpu().detach().numpy()\n",
        "    y_pred = torch.stack(y_pred).cpu().detach().numpy()\n",
        "    y = [y_true, y_pred]\n",
        "    loss = np.mean(losses)\n",
        "\n",
        "    return y, loss\n",
        "\n",
        "\n",
        "def eval_op(model, data_loader, loss_fn):\n",
        "    model.eval()\n",
        "\n",
        "    losses = []\n",
        "    y_pred = []\n",
        "    y_true = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for dl in tqdm(data_loader, total=len(data_loader), desc=\"Evaluation... \"):\n",
        "\n",
        "            # Define input_ids, attention_mask, token_type_ids, targets\n",
        "            ##############################################################################################\n",
        "            #                                       Your Code                                            #\n",
        "            ##############################################################################################\n",
        "\n",
        "\n",
        "            # move tensors to GPU if CUDA is available\n",
        "            input_ids = input_ids.to(device)\n",
        "            attention_mask = attention_mask.to(device)\n",
        "            token_type_ids = token_type_ids.to(device)\n",
        "            targets = targets.to(device)\n",
        "\n",
        "            # compute predicted outputs by passing inputs to the model\n",
        "            ##############################################################################################\n",
        "            #                                       Your Code                                            #\n",
        "            ##############################################################################################\n",
        "            \n",
        "            # convert output probabilities to predicted class\n",
        "            ##############################################################################################\n",
        "            #                                       Your Code                                            #\n",
        "            ##############################################################################################\n",
        "\n",
        "            # calculate the batch loss\n",
        "            ##############################################################################################\n",
        "            #                                       Your Code                                            #\n",
        "            ##############################################################################################\n",
        "\n",
        "            # accumulate all the losses\n",
        "            losses.append(loss.item())\n",
        "\n",
        "            y_pred.extend(preds)\n",
        "            y_true.extend(targets)\n",
        "    \n",
        "    eval_y, eval_loss = y_loss(y_true, y_pred, losses)\n",
        "    return eval_y, eval_loss\n",
        "\n",
        "\n",
        "def train_op(model, \n",
        "             data_loader, \n",
        "             loss_fn, \n",
        "             optimizer, \n",
        "             scheduler, \n",
        "             step=0, \n",
        "             print_every_step=100, \n",
        "             eval=False,\n",
        "             eval_cb=None,\n",
        "             eval_loss_min=np.Inf,\n",
        "             eval_data_loader=None, \n",
        "             clip=0.0):\n",
        "    \n",
        "    model.train()\n",
        "\n",
        "    losses = []\n",
        "    y_pred = []\n",
        "    y_true = []\n",
        "\n",
        "    for dl in tqdm(data_loader, total=len(data_loader), desc=\"Training... \"):\n",
        "        step += 1\n",
        "\n",
        "        # Define input_ids, attention_mask, token_type_ids, targets\n",
        "        ##############################################################################################\n",
        "        #                                       Your Code                                            #\n",
        "        ##############################################################################################\n",
        "\n",
        "        # move tensors to GPU if CUDA is available\n",
        "        input_ids = input_ids.to(device)\n",
        "        attention_mask = attention_mask.to(device)\n",
        "        token_type_ids = token_type_ids.to(device)\n",
        "        targets = targets.to(device)\n",
        "\n",
        "        # clear the gradients of all optimized variables\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # compute predicted outputs by passing inputs to the model\n",
        "        ##############################################################################################\n",
        "        #                                       Your Code                                            #\n",
        "        ##############################################################################################\n",
        "        \n",
        "        # convert output probabilities to predicted class\n",
        "        ##############################################################################################\n",
        "        #                                       Your Code                                            #\n",
        "        ##############################################################################################\n",
        "\n",
        "        # calculate the batch loss\n",
        "        ##############################################################################################\n",
        "        #                                       Your Code                                            #\n",
        "        ##############################################################################################\n",
        "\n",
        "        # accumulate all the losses\n",
        "        losses.append(loss.item())\n",
        "\n",
        "        # compute gradient of the loss with respect to model parameters\n",
        "        loss.backward()\n",
        "\n",
        "        # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
        "        if clip > 0.0:\n",
        "            nn.utils.clip_grad_norm_(model.parameters(), max_norm=clip)\n",
        "\n",
        "        # perform optimization step\n",
        "        optimizer.step()\n",
        "\n",
        "        # perform scheduler step\n",
        "        scheduler.step()\n",
        "\n",
        "        y_pred.extend(preds)\n",
        "        y_true.extend(targets)\n",
        "\n",
        "        if eval:\n",
        "            train_y, train_loss = y_loss(y_true, y_pred, losses)\n",
        "            train_score = acc_and_f1(train_y[0], train_y[1], average='weighted')\n",
        "\n",
        "            if step % print_every_step == 0:\n",
        "                eval_y, eval_loss = eval_op(model, eval_data_loader, loss_fn)\n",
        "                eval_score = acc_and_f1(eval_y[0], eval_y[1], average='weighted')\n",
        "\n",
        "                if hasattr(eval_cb, '__call__'):\n",
        "                    eval_loss_min = eval_cb(model, step, train_score, train_loss, eval_score, eval_loss, eval_loss_min)\n",
        "\n",
        "    train_y, train_loss = y_loss(y_true, y_pred, losses)\n",
        "\n",
        "    return train_y, train_loss, step, eval_loss_min"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**<font color=red> Define Optimizer, Scheduler & Loss Function</font>**"
      ],
      "metadata": {
        "id": "H1vqogQgbCiH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "wTWrdialDAtN"
      },
      "outputs": [],
      "source": [
        "#######################################Your Code#############################################\n",
        "#optimizer = \n",
        "#scheduler =\n",
        "#loss_fn =                                                                                 \n",
        "##############################################################################################\n",
        "\n",
        "step = 0\n",
        "eval_loss_min = np.Inf\n",
        "history = collections.defaultdict(list)\n",
        "\n",
        "\n",
        "def eval_callback(epoch, epochs, output_path):\n",
        "    def eval_cb(model, step, train_score, train_loss, eval_score, eval_loss, eval_loss_min):\n",
        "        statement = ''\n",
        "        statement += 'Epoch: {}/{}...'.format(epoch, epochs)\n",
        "        statement += 'Step: {}...'.format(step)\n",
        "        \n",
        "        statement += 'Train Loss: {:.6f}...'.format(train_loss)\n",
        "        statement += 'Train Acc: {:.3f}...'.format(train_score['acc'])\n",
        "\n",
        "        statement += 'Valid Loss: {:.6f}...'.format(eval_loss)\n",
        "        statement += 'Valid Acc: {:.3f}...'.format(eval_score['acc'])\n",
        "\n",
        "        print(statement)\n",
        "\n",
        "        if eval_loss <= eval_loss_min:\n",
        "            print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
        "                eval_loss_min,\n",
        "                eval_loss))\n",
        "            \n",
        "            torch.save(model.state_dict(), output_path)\n",
        "            eval_loss_min = eval_loss\n",
        "        \n",
        "        return eval_loss_min\n",
        "\n",
        "\n",
        "    return eval_cb\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**<font color=red> Complete Training & Plot Loss and Accuracy Diagram</font>**"
      ],
      "metadata": {
        "id": "4ph_-AxZkcvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in tqdm(range(1, EPOCHS + 1), desc=\"Epochs... \"):\n",
        "\n",
        "    # Define train_y, train_loss, step, eval_loss_min using train_op\n",
        "    ##############################################################################################\n",
        "    #                                       Your Code                                            #\n",
        "    ##############################################################################################\n",
        "    \n",
        "    # Define train_score using acc_and_f1\n",
        "    ##############################################################################################\n",
        "    #                                       Your Code                                            #\n",
        "    ##############################################################################################\n",
        "    \n",
        "    # Define eval_y, eval_loss using eval_op\n",
        "    ##############################################################################################\n",
        "    #                                       Your Code                                            #\n",
        "    ##############################################################################################\n",
        "    \n",
        "    # Define eval_score using acc_and_f1\n",
        "    ##############################################################################################\n",
        "    #                                       Your Code                                            #\n",
        "    ##############################################################################################\n",
        "    \n",
        "    # Save Accuracy and Loss values\n",
        "    ##############################################################################################\n",
        "    #                                       Your Code                                            #\n",
        "    ##############################################################################################\n",
        "\n",
        "\n",
        "# Diagram\n",
        "##############################################################################################\n",
        "#                                       Your Code                                            #\n",
        "##############################################################################################"
      ],
      "metadata": {
        "id": "7i42uhBMkbEy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-ZvVuRsoYRK"
      },
      "source": [
        "### Prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**<font color=red> Complete function</font>**"
      ],
      "metadata": {
        "id": "a4rSonLZjzrL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dlpDbg0wDqKP"
      },
      "outputs": [],
      "source": [
        "def predict(model, comments, tokenizer, max_len=128, batch_size=32):\n",
        "    data_loader = create_data_loader(comments, None, tokenizer, max_len, batch_size, None)\n",
        "    \n",
        "    predictions = []\n",
        "    prediction_probs = []\n",
        "\n",
        "    \n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for dl in tqdm(data_loader, position=0):\n",
        "\n",
        "            # Define input_ids, attention_mask, token_type_ids\n",
        "            ##############################################################################################\n",
        "            #                                       Your Code                                            #\n",
        "            ##############################################################################################\n",
        "\n",
        "            # move tensors to GPU if CUDA is available\n",
        "            input_ids = input_ids.to(device)\n",
        "            attention_mask = attention_mask.to(device)\n",
        "            token_type_ids = token_type_ids.to(device)\n",
        "            \n",
        "            # compute predicted outputs by passing inputs to the model\n",
        "            ##############################################################################################\n",
        "            #                                       Your Code                                            #\n",
        "            ##############################################################################################\n",
        "            \n",
        "            # convert output probabilities to predicted class\n",
        "            ##############################################################################################\n",
        "            #                                       Your Code                                            #\n",
        "            ##############################################################################################\n",
        "\n",
        "            predictions.extend(preds)\n",
        "            prediction_probs.extend(F.softmax(outputs, dim=1))\n",
        "\n",
        "    predictions = torch.stack(predictions).cpu().detach().numpy()\n",
        "    prediction_probs = torch.stack(prediction_probs).cpu().detach().numpy()\n",
        "\n",
        "    return predictions, prediction_probs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RRpWTfwdoWoS"
      },
      "outputs": [],
      "source": [
        "test_comments = test['comment'].to_numpy()\n",
        "preds, probs = predict(pt_model, test_comments, tokenizer, max_len=128)\n",
        "\n",
        "print(preds.shape, probs.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**<font color=red> Evaluate Your Model using f1-score & Precision & Recall</font>**"
      ],
      "metadata": {
        "id": "FJ_GfqNck5he"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZRL2bgDDpUG0"
      },
      "outputs": [],
      "source": [
        "##############################################################################################\n",
        "#                                       Your Code                                            #\n",
        "##############################################################################################"
      ]
    }
  ]
}